{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b0da0e-8cc3-4bcb-bd10-cab521c18d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, log_loss, cohen_kappa_score, matthews_corrcoef,\n",
    "    top_k_accuracy_score, classification_report, roc_curve,\n",
    "    auc, roc_auc_score, f1_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from xgboost.callback import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b26b7f60-842b-4be3-9bb0-865445d4d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = None\n",
    "newsgroups = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=5)\n",
    "X, y = newsgroups.data, newsgroups.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90dc9a8d-db26-4fa6-95aa-2c68e02f68e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multiclass_model(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    y_score,\n",
    "    class_names,\n",
    "    top_k=3,\n",
    "    show_report=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate a multi-class classification model and return metrics as a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - y_test: True labels (integers)\n",
    "    - y_pred: Predicted labels (integers)\n",
    "    - y_score: Predicted class probabilities (shape: [n_samples, n_classes])\n",
    "    - class_names: List of class names (strings)\n",
    "    - top_k: Value of k for Top-k Accuracy (default: 3)\n",
    "    - show_report: Whether to return the classification report (default: False)\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "\n",
    "    n_classes = len(class_names)\n",
    "    y_test_bin = label_binarize(y_test, classes=range(n_classes))\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"log_loss\": log_loss(y_test, y_score),\n",
    "        \"f1_macro\": f1_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"f1_weighted\": f1_score(y_test, y_pred, average=\"weighted\"),\n",
    "        \"cohen_kappa\": cohen_kappa_score(y_test, y_pred),\n",
    "        \"mcc\": matthews_corrcoef(y_test, y_pred),\n",
    "        f\"top_{top_k}_accuracy\": top_k_accuracy_score(y_test, y_score, k=top_k),\n",
    "        \"macro_auc\": roc_auc_score(y_test_bin, y_score, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "    if show_report:\n",
    "        metrics[\"classification_report\"] = classification_report(\n",
    "            y_test, y_pred, target_names=class_names, output_dict=True\n",
    "        )\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3a755b-23ac-467e-9f38-81bf12c9cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiclass_roc(y_test, y_score, class_names):\n",
    "    \"\"\"\n",
    "    Plot ROC curves for multi-class classification using One-vs-Rest approach.\n",
    "\n",
    "    Parameters:\n",
    "    - y_test: True labels (integers)\n",
    "    - y_score: Predicted probabilities (shape: [n_samples, n_classes])\n",
    "    - class_names: List of class names\n",
    "    \"\"\"\n",
    "    n_classes = len(class_names)\n",
    "    y_test_bin = label_binarize(y_test, classes=range(n_classes))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves (One-vs-Rest)\")\n",
    "    plt.legend(loc=\"lower right\", fontsize='small')\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc71b90f-80af-472c-8139-c0bab96361ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "#    \"Naive Bayes\": MultinomialNB(),\n",
    "#    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "#    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#    \"LightGBM\": LGBMClassifier(\n",
    "#        n_estimators=1000,\n",
    "#        learning_rate=0.05,\n",
    "#        max_depth=8,\n",
    "#        num_leaves=64,\n",
    "#        subsample=0.8,\n",
    "#        colsample_bytree=0.8,\n",
    "#        random_state=5,\n",
    "#        verbose=-1\n",
    "#    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"mlogloss\",    \n",
    "        tree_method=\"hist\",  \n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d68cd4d5-d2e5-49c4-920f-de3cd653211f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: XGBoost\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m X_test_vec \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# 最新API：early stopping を callbacks に明示\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_vec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_part\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_part\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ← これだけでOK\u001b[39;49;00m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     49\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test_vec)\n\u001b[1;32m     52\u001b[0m y_score \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_vec)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/20-newsgroups/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    print(f\"Evaluating: {model_name}\")\n",
    "    \n",
    "    if model_name == \"LightGBM\":\n",
    "        # TF-IDF + early stopping\n",
    "        X_train_part, X_val_part, y_train_part, y_val_part = train_test_split(\n",
    "            X_train, y_train, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # TF-IDF\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_train_vec = vectorizer.fit_transform(X_train_part)\n",
    "        X_val_vec = vectorizer.transform(X_val_part)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "        clf.fit(\n",
    "            X_train_vec, y_train_part,\n",
    "            eval_set=[(X_val_vec, y_val_part)],\n",
    "            eval_metric=\"multi_logloss\",\n",
    "            callbacks=[\n",
    "                early_stopping(stopping_rounds=20),\n",
    "                log_evaluation(period=0)  # no verbosity\n",
    "            ]\n",
    "        )\n",
    "        y_pred = clf.predict(X_test_vec)\n",
    "        y_score = clf.predict_proba(X_test_vec)\n",
    "\n",
    "\n",
    "    elif model_name == \"XGBoost\":\n",
    "        X_train_part, X_val_part, y_train_part, y_val_part = train_test_split(\n",
    "            X_train, y_train, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_train_vec = vectorizer.fit_transform(X_train_part)\n",
    "        X_val_vec = vectorizer.transform(X_val_part)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "        clf.fit(\n",
    "            X_train_vec,\n",
    "            y_train_part,\n",
    "            eval_set=[(X_val_vec, y_val_part)],\n",
    "            early_stopping_rounds=20,   \n",
    "            verbose=False\n",
    "        )\n",
    "    \n",
    "        y_pred = clf.predict(X_test_vec)\n",
    "        y_score = clf.predict_proba(X_test_vec)\n",
    "\n",
    "\n",
    "    else:\n",
    "        model = make_pipeline(TfidfVectorizer(), clf)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_score = model.predict_proba(X_test)\n",
    "\n",
    "    results = evaluate_multiclass_model(\n",
    "        y_test=y_test,\n",
    "        y_pred=y_pred,\n",
    "        y_score=y_score,\n",
    "        class_names=newsgroups.target_names,\n",
    "        show_report=False\n",
    "    )\n",
    "    results[\"model\"] = model_name\n",
    "    all_results.append(results)\n",
    "\n",
    "    plot_multiclass_roc(\n",
    "        y_test=y_test,\n",
    "        y_score=y_score,\n",
    "        class_names=newsgroups.target_names\n",
    "    )\n",
    "\n",
    "df_all = pd.DataFrame(all_results).set_index(\"model\").round(4)\n",
    "display(df_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a08854-f72a-4501-aeda-5e9f0128ed84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08637678-0367-4e9b-bf74-2779dfce51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "print(xgboost.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80b28b-ab59-4f86-9239-8fd8f11bae2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1215ab90-53b0-4077-85cf-67687e3136b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9368f9db-f825-43f8-a6d0-a2a35b650db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b03a0-39fa-4e62-9f19-2f0c59fa592f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b97de78-9453-44e2-8f50-4abdd1f5500c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.1\n",
      "xgboost.sklearn\n",
      "1.6.1\n",
      "3.10.16 (main, Dec 11 2024, 10:22:29) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import xgboost; print(xgboost.__version__)\n",
    "from xgboost import XGBClassifier; print(XGBClassifier.__module__)\n",
    "import sklearn; print(sklearn.__version__)\n",
    "import sys; print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec4eaa82-837d-4646-814d-38792aa12d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost.sklearn\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "902a640c-2f0c-4997-8624-296a4697b739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb18681-7758-49a1-8b5b-35e0a8eacc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0022f4-9619-4ab6-bf71-2b9bda678116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec337e74-98c0-4e36-872c-737976e3d254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
